{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../../1_Data_Cleaning/Dataset_Facebook_Bretschneider_Peters_2016/comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate label from valence\n",
    "def computeLabel(val):\n",
    "    value = val.split(',') if isinstance(val, str) else False\n",
    "    if(value):\n",
    "        return int(sum(map(int,value)) / len(value))\n",
    "    else:\n",
    "        return 0\n",
    "df['label'] = df['valence'].apply(lambda x: computeLabel(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary label from label\n",
    "df['binary_label'] = df['valence'].apply(lambda x: computeLabel(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>valence</th>\n",
       "      <th>expert_ids</th>\n",
       "      <th>target_type</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gleich an die wand stellen und erschiessen..</td>\n",
       "      <td>d766dfb93914e8da</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1,3</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1</td>\n",
       "      <td>tja .... das Ergebniss ungebremsten Zuzug ...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nicht dass ich der Grundbotschaft dieses Post'...</td>\n",
       "      <td>6e49f84e2a5a1f05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>tja .... das Ergebniss ungebremsten Zuzug ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Das mit dem \"an die Wand stellen und erschiessen\"</td>\n",
       "      <td>6ab1ef4615c45a79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>tja .... das Ergebniss ungebremsten Zuzug ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Seit dem \"an die Wand stellen und erschiessen\"...</td>\n",
       "      <td>6ab1ef4615c45a79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>tja .... das Ergebniss ungebremsten Zuzug ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ja ja die Kriminelle Heimatpartei FPÖ von Kind...</td>\n",
       "      <td>03c34eadeee054d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>tja .... das Ergebniss ungebremsten Zuzug ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                            comment  \\\n",
       "0           1       gleich an die wand stellen und erschiessen..   \n",
       "1           2  nicht dass ich der Grundbotschaft dieses Post'...   \n",
       "2           3  Das mit dem \"an die Wand stellen und erschiessen\"   \n",
       "3           4  Seit dem \"an die Wand stellen und erschiessen\"...   \n",
       "4           5  Ja ja die Kriminelle Heimatpartei FPÖ von Kind...   \n",
       "\n",
       "             author valence expert_ids target_type  post_id  \\\n",
       "0  d766dfb93914e8da     2,2        1,3         2,2        1   \n",
       "1  6e49f84e2a5a1f05     NaN        NaN         NaN        1   \n",
       "2  6ab1ef4615c45a79     NaN        NaN         NaN        1   \n",
       "3  6ab1ef4615c45a79     NaN        NaN         NaN        1   \n",
       "4  03c34eadeee054d7     NaN        NaN         NaN        1   \n",
       "\n",
       "                                            post  label  binary_label  \n",
       "0  tja .... das Ergebniss ungebremsten Zuzug ...      2          True  \n",
       "1  tja .... das Ergebniss ungebremsten Zuzug ...      0         False  \n",
       "2  tja .... das Ergebniss ungebremsten Zuzug ...      0         False  \n",
       "3  tja .... das Ergebniss ungebremsten Zuzug ...      0         False  \n",
       "4  tja .... das Ergebniss ungebremsten Zuzug ...      0         False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_helpers import clean_input as ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_cleaned'] = df['comment'].apply(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs = df.filter(['comment', 'comment_cleaned', 'label', 'binary_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>label</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gleich an die wand stellen und erschiessen..</td>\n",
       "      <td>gleich wand stellen erschiessen</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nicht dass ich der Grundbotschaft dieses Post'...</td>\n",
       "      <td>das grundbotschaft post widersprechen 1 rechts...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das mit dem \"an die Wand stellen und erschiessen\"</td>\n",
       "      <td>wand stellen erschiessen</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seit dem \"an die Wand stellen und erschiessen\"...</td>\n",
       "      <td>seit wand stellen erschiessen deutschland etwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ja ja die Kriminelle Heimatpartei FPÖ von Kind...</td>\n",
       "      <td>ja ja kriminelle heimatpartei fpö kinderpornog...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ihr seids empfindlich . . Is beste wos uns pas...</td>\n",
       "      <td>seids empfindlich is beste wos passieren is he...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mei bitte, sie sollen sich alle gegenseitig ab...</td>\n",
       "      <td>mei bitte sollen gegenseitig abstechen problem...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wahnsinn.... :-(</td>\n",
       "      <td>wahnsinn</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alles nur traumatisierte Kindlein.  Die von de...</td>\n",
       "      <td>traumatisierte kindlein grünen bezahlten anwäl...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fachkräfte bei der Arbeit. Ein Hirnchirurg und...</td>\n",
       "      <td>fachkräfte arbeit hirnchirurg atomphysiker</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unglaublich, was für ausländerfeindliche Komme...</td>\n",
       "      <td>unglaublich ausländerfeindliche kommentare imm...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ich staune nur daß in österreich dieses proble...</td>\n",
       "      <td>staune österreich problem rasch ankam eigentli...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Das ist multi Kulti</td>\n",
       "      <td>multi kulti</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Es soll doch jeder in sein eigenen Land bleibe...</td>\n",
       "      <td>eigenen land bleibenda untereinander totschlagen</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Supie! Sie löschen sich gegenseitig aus! Hoffe...</td>\n",
       "      <td>supie löschen gegenseitig hoffentlich bald</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jagt dieses Dreckspack raus.</td>\n",
       "      <td>jagt dreckspack raus</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>die regierung will es doch so ,polizei schaut ...</td>\n",
       "      <td>regierung polizei schaut bitte lass mal selber...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>weiter so freut mich das alle gutmenschen aufw...</td>\n",
       "      <td>freut gutmenschen aufwachen</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>beide volksgruppen sofort ausweisen das eizige...</td>\n",
       "      <td>beide volksgruppen sofort ausweisen eizige leg...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>warum hauen die ösis nicht drauf die könnens d...</td>\n",
       "      <td>warum hauen ösis drauf könnens geschichte daue...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment  \\\n",
       "0        gleich an die wand stellen und erschiessen..   \n",
       "1   nicht dass ich der Grundbotschaft dieses Post'...   \n",
       "2   Das mit dem \"an die Wand stellen und erschiessen\"   \n",
       "3   Seit dem \"an die Wand stellen und erschiessen\"...   \n",
       "4   Ja ja die Kriminelle Heimatpartei FPÖ von Kind...   \n",
       "5   Ihr seids empfindlich . . Is beste wos uns pas...   \n",
       "6   Mei bitte, sie sollen sich alle gegenseitig ab...   \n",
       "7                                    Wahnsinn.... :-(   \n",
       "8   Alles nur traumatisierte Kindlein.  Die von de...   \n",
       "9   Fachkräfte bei der Arbeit. Ein Hirnchirurg und...   \n",
       "10  Unglaublich, was für ausländerfeindliche Komme...   \n",
       "11  ich staune nur daß in österreich dieses proble...   \n",
       "12                                Das ist multi Kulti   \n",
       "13  Es soll doch jeder in sein eigenen Land bleibe...   \n",
       "14  Supie! Sie löschen sich gegenseitig aus! Hoffe...   \n",
       "15                       jagt dieses Dreckspack raus.   \n",
       "16  die regierung will es doch so ,polizei schaut ...   \n",
       "17  weiter so freut mich das alle gutmenschen aufw...   \n",
       "18  beide volksgruppen sofort ausweisen das eizige...   \n",
       "19  warum hauen die ösis nicht drauf die könnens d...   \n",
       "\n",
       "                                      comment_cleaned  label  binary_label  \n",
       "0                     gleich wand stellen erschiessen      2          True  \n",
       "1   das grundbotschaft post widersprechen 1 rechts...      0         False  \n",
       "2                            wand stellen erschiessen      0         False  \n",
       "3   seit wand stellen erschiessen deutschland etwa...      0         False  \n",
       "4   ja ja kriminelle heimatpartei fpö kinderpornog...      0         False  \n",
       "5   seids empfindlich is beste wos passieren is he...      2          True  \n",
       "6   mei bitte sollen gegenseitig abstechen problem...      2          True  \n",
       "7                                           wahnsinn       0         False  \n",
       "8   traumatisierte kindlein grünen bezahlten anwäl...      0         False  \n",
       "9          fachkräfte arbeit hirnchirurg atomphysiker      0         False  \n",
       "10  unglaublich ausländerfeindliche kommentare imm...      2          True  \n",
       "11  staune österreich problem rasch ankam eigentli...      0         False  \n",
       "12                                        multi kulti      0         False  \n",
       "13   eigenen land bleibenda untereinander totschlagen      0         False  \n",
       "14         supie löschen gegenseitig hoffentlich bald      1          True  \n",
       "15                               jagt dreckspack raus      2          True  \n",
       "16  regierung polizei schaut bitte lass mal selber...      0         False  \n",
       "17                        freut gutmenschen aufwachen      0         False  \n",
       "18  beide volksgruppen sofort ausweisen eizige leg...      0         False  \n",
       "19  warum hauen ösis drauf könnens geschichte daue...      0         False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split virgin dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hs['comment_cleaned'], df_hs['binary_label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5162\n",
      "2     374\n",
      "1     300\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df_hs.label.value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    5162\n",
      "True      674\n",
      "Name: binary_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df_hs.binary_label.value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Labels sind sehr ungleich verteilt. Ausgleich (bei Trainingsdaten) mit SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\pascal\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\pascal\\anaconda3\\lib\\site-packages (from imblearn) (0.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\pascal\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\pascal\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\pascal\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# install imblearn\n",
    "import sys\n",
    "!{sys.executable} -m pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(False, 4115), (True, 4115)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y_train_res, return_counts=True)\n",
    "print(list(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8705953827460511"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "\n",
    "y_pred = rf.predict(X_test_vect)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.04%\n",
      "\n",
      "F1 Score: 32.63\n",
      "\n",
      "COnfusion Matrix:\n",
      " [[1009   38]\n",
      " [  90   31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print(\"\\nF1 Score: {:.2f}\".format(f1_score(y_test, y_pred) * 100))\n",
    "print(\"\\nCOnfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.436 / Recall: 0.262 / Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary')\n",
    "                                           \n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), \n",
    "                                                         round(recall, 3), \n",
    "                                                         round((y_pred==y_test).sum() / len(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average accuracy across folds: 88.66%\n",
      "\n",
      "Average F1 score across folds: 34.35%\n",
      "\n",
      "Average Confusion Matrix across folds: \n",
      " [[1000.7   35.5]\n",
      " [  96.9   34.9]]\n"
     ]
    }
   ],
   "source": [
    "# a monte carlo method\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "X = df_hs.comment_cleaned\n",
    "y = df.binary_label\n",
    "\n",
    "ss = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "sm = SMOTE()\n",
    "\n",
    "accs = []\n",
    "f1s = []\n",
    "cms = []\n",
    "\n",
    "for train_index, test_index in ss.split(X):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit vectorizer and transform X train, then transform X test\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    X_test_vect = vect.transform(X_test)\n",
    "    \n",
    "    # Oversample\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)\n",
    "    \n",
    "    # Fit Naive Bayes on the vectorized X with y train labels, \n",
    "    # then predict new y labels using X test\n",
    "    rf.fit(X_train_res, y_train_res)\n",
    "    y_pred = rf.predict(X_test_vect)\n",
    "    \n",
    "    # Determine test set accuracy and f1 score on this fold using the true y labels and predicted y labels\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    cms.append(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(sum(accs) / len(accs) * 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(sum(f1s) / len(f1s) * 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(sum(cms) / len(cms)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
