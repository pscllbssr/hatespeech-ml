{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ist ekelhaft  bei ihren Klos kannst du nur mit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bevor Sie mit Jud...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Und de Amis freut es wenn die Heuschrecken Eur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:    Die Krim ist ein heißer Tip, auch zum In...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Es muss in #Deutschland eine politische Kra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label\n",
       "0  ist ekelhaft  bei ihren Klos kannst du nur mit...       0.0         False\n",
       "1                               Bevor Sie mit Jud...       1.0          True\n",
       "2  Und de Amis freut es wenn die Heuschrecken Eur...       0.0         False\n",
       "3   :    Die Krim ist ein heißer Tip, auch zum In...       1.0          True\n",
       "4   : Es muss in #Deutschland eine politische Kra...       1.0          True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../2_Feature_Engineering/export/combined_polly_bretschneider_iwg.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'..\\..\\0_common')\n",
    "from model_helpers import clean_all as ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ist ekelhaft  bei ihren Klos kannst du nur mit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>ekelhaft klos kannst gummistiefel gehen stinkt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bevor Sie mit Jud...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>bevor judenstern markiert worden juden ganze ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Und de Amis freut es wenn die Heuschrecken Eur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>de amis freut heuschrecken europa klein wirtsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:    Die Krim ist ein heißer Tip, auch zum In...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>krim heißer tip investieren muß bürger landes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Es muss in #Deutschland eine politische Kra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>deutschland politische kraft geben sozial sch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label  \\\n",
       "0  ist ekelhaft  bei ihren Klos kannst du nur mit...       0.0         False   \n",
       "1                               Bevor Sie mit Jud...       1.0          True   \n",
       "2  Und de Amis freut es wenn die Heuschrecken Eur...       0.0         False   \n",
       "3   :    Die Krim ist ein heißer Tip, auch zum In...       1.0          True   \n",
       "4   : Es muss in #Deutschland eine politische Kra...       1.0          True   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ekelhaft klos kannst gummistiefel gehen stinkt...  \n",
       "1   bevor judenstern markiert worden juden ganze ...  \n",
       "2  de amis freut heuschrecken europa klein wirtsc...  \n",
       "3   krim heißer tip investieren muß bürger landes...  \n",
       "4   deutschland politische kraft geben sozial sch...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['raw_text'].apply(ci)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9169, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,3), analyzer='word', max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = vec.fit_transform(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9169, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_score(features, labels, clf):\n",
    "    \n",
    "    # split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=True)\n",
    "    \n",
    "    #train    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # score\n",
    "    from sklearn.metrics import precision_recall_fscore_support as score\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary')\n",
    "    \n",
    "    # confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    m_df = pd.DataFrame(\n",
    "    matrix, \n",
    "    columns=[\"Negatives\", \"Positives\"],\n",
    "    index=[\"Negatives\", \"Positives\"])\n",
    "    \n",
    "    return fscore, precision, recall, m_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algo(key, clf):\n",
    "    scores[key] = []\n",
    "    matrices[key] = []\n",
    "\n",
    "    for i in range(10):\n",
    "        fscore, precision, recall, confusion_matrix = split_train_score(X_features, df['binary_label'], clf)\n",
    "        scores[key].append([fscore, precision, recall])\n",
    "        matrices[key].append(confusion_matrix)\n",
    "\n",
    "    scores_df = pd.DataFrame(scores[key], columns=['fscore', 'precision', 'recall']) \n",
    "    fscore_avg = round(scores_df['fscore'].mean(),3)\n",
    "    prec_avg = round(scores_df['precision'].mean(),3)\n",
    "    rec_avg = round(scores_df['recall'].mean(),3)\n",
    "    \n",
    "    '''\n",
    "    print(key.upper())\n",
    "    print('---')\n",
    "    print('Fscore: ', fscore_avg)\n",
    "    print('Min/Max: {} / {} '.format(round(scores_df['fscore'].max(), 3), round(scores_df['fscore'].min(),3)))\n",
    "    '''\n",
    "    \n",
    "    return fscore_avg, prec_avg, rec_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "algos = {\n",
    "    'lr': LogisticRegression(),\n",
    "    'dct': DecisionTreeClassifier(),\n",
    "    'bnb': BernoulliNB(),\n",
    "    'mnb': MultinomialNB(),\n",
    "    'svm': SGDClassifier(),\n",
    "    'rf': RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fscore  precision  recall\n",
      "rf    0.881      0.906   0.857\n",
      "dct   0.879      0.880   0.878\n",
      "svm   0.853      0.872   0.836\n",
      "lr    0.835      0.858   0.814\n",
      "mnb   0.817      0.867   0.773\n",
      "bnb   0.752      0.946   0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fscore  precision  recall\n",
      "rf    0.883      0.912   0.857\n",
      "dct   0.877      0.879   0.875\n",
      "svm   0.856      0.869   0.844\n",
      "lr    0.838      0.863   0.815\n",
      "mnb   0.816      0.861   0.776\n",
      "bnb   0.742      0.946   0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fscore  precision  recall\n",
      "dct   0.881      0.882   0.881\n",
      "rf    0.877      0.901   0.855\n",
      "svm   0.856      0.874   0.840\n",
      "lr    0.829      0.855   0.805\n",
      "mnb   0.815      0.861   0.774\n",
      "bnb   0.742      0.944   0.611\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):    \n",
    "    results = {}\n",
    "\n",
    "    for index, clf in algos.items():\n",
    "        fscore, precision, recall = evaluate_algo(index, clf)\n",
    "        results[index] = [fscore, precision, recall]\n",
    "\n",
    "    result_df = pd.DataFrame.from_dict(results, orient = 'index', columns=['fscore', 'precision', 'recall']).sort_values('fscore', ascending=False)\n",
    "    print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
