{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ist ekelhaft  bei ihren Klos kannst du nur mit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bevor Sie mit Jud...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Und de Amis freut es wenn die Heuschrecken Eur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:    Die Krim ist ein heißer Tip, auch zum In...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Es muss in #Deutschland eine politische Kra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label\n",
       "0  ist ekelhaft  bei ihren Klos kannst du nur mit...       0.0         False\n",
       "1                               Bevor Sie mit Jud...       1.0          True\n",
       "2  Und de Amis freut es wenn die Heuschrecken Eur...       0.0         False\n",
       "3   :    Die Krim ist ein heißer Tip, auch zum In...       1.0          True\n",
       "4   : Es muss in #Deutschland eine politische Kra...       1.0          True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../2_Feature_Engineering/export/combined_polly_bretschneider_iwg.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'..\\..\\0_common')\n",
    "from model_helpers import clean_all as ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ist ekelhaft  bei ihren Klos kannst du nur mit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>ekelhaft klos kannst gummistiefel gehen stinkt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bevor Sie mit Jud...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>bevor judenstern markiert worden juden ganze ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Und de Amis freut es wenn die Heuschrecken Eur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>de amis freut heuschrecken europa klein wirtsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:    Die Krim ist ein heißer Tip, auch zum In...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>krim heißer tip investieren muß bürger landes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Es muss in #Deutschland eine politische Kra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>deutschland politische kraft geben sozial sch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label  \\\n",
       "0  ist ekelhaft  bei ihren Klos kannst du nur mit...       0.0         False   \n",
       "1                               Bevor Sie mit Jud...       1.0          True   \n",
       "2  Und de Amis freut es wenn die Heuschrecken Eur...       0.0         False   \n",
       "3   :    Die Krim ist ein heißer Tip, auch zum In...       1.0          True   \n",
       "4   : Es muss in #Deutschland eine politische Kra...       1.0          True   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ekelhaft klos kannst gummistiefel gehen stinkt...  \n",
       "1   bevor judenstern markiert worden juden ganze ...  \n",
       "2  de amis freut heuschrecken europa klein wirtsc...  \n",
       "3   krim heißer tip investieren muß bürger landes...  \n",
       "4   deutschland politische kraft geben sozial sch...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['raw_text'].apply(ci)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9169, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(3,5), analyzer='char_wb', max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = vec.fit_transform(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9169, 74355)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(clf, X_features, df['binary_label'], cv=5,\n",
    "                        scoring=('f1', 'roc_auc', 'precision', 'recall'),\n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fit_time',\n",
       " 'score_time',\n",
       " 'test_f1',\n",
       " 'test_precision',\n",
       " 'test_recall',\n",
       " 'test_roc_auc',\n",
       " 'train_f1',\n",
       " 'train_precision',\n",
       " 'train_recall',\n",
       " 'train_roc_auc']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.690349</td>\n",
       "      <td>1.323895</td>\n",
       "      <td>0.908146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.925100</td>\n",
       "      <td>1.302445</td>\n",
       "      <td>0.928612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940972</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.712773</td>\n",
       "      <td>1.318674</td>\n",
       "      <td>0.915332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.818397</td>\n",
       "      <td>1.312382</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.718653</td>\n",
       "      <td>1.314856</td>\n",
       "      <td>0.927355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.946698</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time   test_f1  train_f1  test_roc_auc  train_roc_auc  \\\n",
       "0  11.690349    1.323895  0.908146       1.0      0.971496            1.0   \n",
       "1  11.925100    1.302445  0.928612       1.0      0.978066            1.0   \n",
       "2  11.712773    1.318674  0.915332       1.0      0.973986            1.0   \n",
       "3  11.818397    1.312382  0.936000       1.0      0.982119            1.0   \n",
       "4  11.718653    1.314856  0.927355       1.0      0.980811            1.0   \n",
       "\n",
       "   test_precision  train_precision  test_recall  train_recall  \n",
       "0        0.906574              1.0     0.909722           1.0  \n",
       "1        0.916573              1.0     0.940972           1.0  \n",
       "2        0.904977              1.0     0.925926           1.0  \n",
       "3        0.924379              1.0     0.947917           1.0  \n",
       "4        0.908788              1.0     0.946698           1.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_f1           0.923089\n",
       "test_roc_auc      0.977296\n",
       "test_precision    0.912258\n",
       "test_recall       0.934247\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "scores_df[['test_f1', 'test_roc_auc', 'test_precision', 'test_recall']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> Random Forest with char n-grams seems to be the best, over all in case of recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finally train and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, df['binary_label'], test_size=0.2, shuffle=True, stratify=df['binary_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=200)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.929 / Fscore: 0.919 / Precision: 0.908\n"
     ]
    }
   ],
   "source": [
    "# show metrics\n",
    "print('Recall: {} / Fscore: {} / Precision: {}'.format(round(recall, 3), \n",
    "                                                             round(fscore, 3),\n",
    "                                                             round(precision, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actually Negative</th>\n",
       "      <td>889</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actually Positive</th>\n",
       "      <td>61</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Negative  Predicted Positive\n",
       "Actually Negative                 889                  81\n",
       "Actually Positive                  61                 803"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show confusion matrix\n",
    "pd.DataFrame(\n",
    "    matrix, \n",
    "    columns=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "    index=[\"Actually Negative\", \"Actually Positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pickle\n",
    "pickle.dump(clf, open('exports/{}_model.pkl'.format('rf3'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export vectorizer\n",
    "pickle.dump(vec, open('exports/char_vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
