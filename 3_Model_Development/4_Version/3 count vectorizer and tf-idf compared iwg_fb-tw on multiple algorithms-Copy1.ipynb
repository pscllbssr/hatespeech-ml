{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich warte schon darauf, dass man die Terrorist...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holt Björn Höcke ins Boot vielleicht haben wir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deutscher, turkmenischer Abstammung bitte. Was...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wer glaubt die gehen wieder , ist einfach nur ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man wünscht sich eine schlagkräftige Bürgerweh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label\n",
       "0  Ich warte schon darauf, dass man die Terrorist...       0.0         False\n",
       "1  Holt Björn Höcke ins Boot vielleicht haben wir...       0.0         False\n",
       "2  Deutscher, turkmenischer Abstammung bitte. Was...       0.0         False\n",
       "3  Wer glaubt die gehen wieder , ist einfach nur ...       0.0         False\n",
       "4  Man wünscht sich eine schlagkräftige Bürgerweh...       0.0         False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../2_Feature_Engineering/export/randomized_balanced_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'..\\..\\0_common')\n",
    "from model_helpers import clean_all as ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich warte schon darauf, dass man die Terrorist...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holt Björn Höcke ins Boot vielleicht haben wir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deutscher, turkmenischer Abstammung bitte. Was...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wer glaubt die gehen wieder , ist einfach nur ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man wünscht sich eine schlagkräftige Bürgerweh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label\n",
       "0  Ich warte schon darauf, dass man die Terrorist...       0.0         False\n",
       "1  Holt Björn Höcke ins Boot vielleicht haben wir...       0.0         False\n",
       "2  Deutscher, turkmenischer Abstammung bitte. Was...       0.0         False\n",
       "3  Wer glaubt die gehen wieder , ist einfach nur ...       0.0         False\n",
       "4  Man wünscht sich eine schlagkräftige Bürgerweh...       0.0         False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['raw_text'].apply(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich warte schon darauf, dass man die Terrorist...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>warte schon darauf das terroristen opfern mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holt Björn Höcke ins Boot vielleicht haben wir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>holt björn höcke boot vielleicht letzte chance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deutscher, turkmenischer Abstammung bitte. Was...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>deutscher turkmenischer abstammung bitte graue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wer glaubt die gehen wieder , ist einfach nur ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wer glaubt gehen einfach blauäugig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man wünscht sich eine schlagkräftige Bürgerweh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wünscht schlagkräftige bürgerwehr sophienhof p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label  \\\n",
       "0  Ich warte schon darauf, dass man die Terrorist...       0.0         False   \n",
       "1  Holt Björn Höcke ins Boot vielleicht haben wir...       0.0         False   \n",
       "2  Deutscher, turkmenischer Abstammung bitte. Was...       0.0         False   \n",
       "3  Wer glaubt die gehen wieder , ist einfach nur ...       0.0         False   \n",
       "4  Man wünscht sich eine schlagkräftige Bürgerweh...       0.0         False   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  warte schon darauf das terroristen opfern mach...  \n",
       "1  holt björn höcke boot vielleicht letzte chance...  \n",
       "2  deutscher turkmenischer abstammung bitte graue...  \n",
       "3                wer glaubt gehen einfach blauäugig   \n",
       "4  wünscht schlagkräftige bürgerwehr sophienhof p...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(2,5), analyzer='char', stop_words='german', max_features=10000)\n",
    "tfidf_wb_vec = TfidfVectorizer(ngram_range=(2,5), analyzer='char_wb', stop_words='german', max_features=10000)\n",
    "count_vec = CountVectorizer(ngram_range=(2,5), analyzer='char', stop_words='german', max_features=10000)\n",
    "count_wb_vec = CountVectorizer(ngram_range=(2,5), analyzer='char_wb', stop_words='german', max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = tfidf_vec.fit_transform(df['cleaned_text'])\n",
    "tfidf_wb_features = tfidf_wb_vec.fit_transform(df['cleaned_text'])\n",
    "count_features = count_vec.fit_transform(df['cleaned_text'])\n",
    "count_wb_features = count_wb_vec.fit_transform(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_wb_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_wb_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_score(features, labels, clf):\n",
    "    \n",
    "    # split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    #train    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # score\n",
    "    from sklearn.metrics import precision_recall_fscore_support as score\n",
    "    y_pred = lr.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary') # pos_label= wenn nicht binary, dann label angeben\n",
    "    \n",
    "    print('Precision: {} / Recall: {} / Accuracy: {} / Fscore: {}'.format(round(precision, 3), \n",
    "                                                         round(recall, 3), \n",
    "                                                         round((y_pred==y_test).sum() / len(y_pred)),\n",
    "                                                         round(fscore, 3)))\n",
    "    # confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    m_df = pd.DataFrame(\n",
    "    matrix, \n",
    "    columns=[\"Negatives\", \"Positives\"],\n",
    "    index=[\"Negatives\", \"Positives\"])\n",
    "    print(m_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'TF-IDF': tfidf_features, 'TF-IDF_with_wb': tfidf_wb_features, 'CountVectorizer': count_features, 'CountVectorizer_with_wb': count_wb_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "Precision: 0.826 / Recall: 0.555 / Accuracy: 1.0 / Fscore: 0.664\n",
      "           Negatives  Positives\n",
      "Negatives        263         30\n",
      "Positives        114        142\n",
      "Precision: 0.822 / Recall: 0.565 / Accuracy: 1.0 / Fscore: 0.67\n",
      "           Negatives  Positives\n",
      "Negatives        265         31\n",
      "Positives        110        143\n",
      "Precision: 0.86 / Recall: 0.629 / Accuracy: 1.0 / Fscore: 0.726\n",
      "           Negatives  Positives\n",
      "Negatives        279         25\n",
      "Positives         91        154\n",
      "\n",
      "TF-IDF_with_wb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.812 / Recall: 0.643 / Accuracy: 1.0 / Fscore: 0.717\n",
      "           Negatives  Positives\n",
      "Negatives        263         37\n",
      "Positives         89        160\n",
      "Precision: 0.809 / Recall: 0.613 / Accuracy: 1.0 / Fscore: 0.697\n",
      "           Negatives  Positives\n",
      "Negatives        265         36\n",
      "Positives         96        152\n",
      "Precision: 0.793 / Recall: 0.607 / Accuracy: 1.0 / Fscore: 0.688\n",
      "           Negatives  Positives\n",
      "Negatives        278         37\n",
      "Positives         92        142\n",
      "\n",
      "CountVectorizer\n",
      "Precision: 0.69 / Recall: 0.702 / Accuracy: 1.0 / Fscore: 0.696\n",
      "           Negatives  Positives\n",
      "Negatives        240         74\n",
      "Positives         70        165\n",
      "Precision: 0.749 / Recall: 0.675 / Accuracy: 1.0 / Fscore: 0.71\n",
      "           Negatives  Positives\n",
      "Negatives        240         57\n",
      "Positives         82        170\n",
      "Precision: 0.742 / Recall: 0.657 / Accuracy: 1.0 / Fscore: 0.697\n",
      "           Negatives  Positives\n",
      "Negatives        248         56\n",
      "Positives         84        161\n",
      "\n",
      "CountVectorizer_with_wb\n",
      "Precision: 0.671 / Recall: 0.694 / Accuracy: 1.0 / Fscore: 0.682\n",
      "           Negatives  Positives\n",
      "Negatives        234         80\n",
      "Positives         72        163\n",
      "Precision: 0.699 / Recall: 0.648 / Accuracy: 1.0 / Fscore: 0.673\n",
      "           Negatives  Positives\n",
      "Negatives        247         66\n",
      "Positives         83        153\n",
      "Precision: 0.694 / Recall: 0.616 / Accuracy: 1.0 / Fscore: 0.653\n",
      "           Negatives  Positives\n",
      "Negatives        254         63\n",
      "Positives         89        143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "for index, option in options.items():\n",
    "    print(index)\n",
    "    split_train_score(option, df['binary_label'], lr)\n",
    "    split_train_score(option, df['binary_label'], lr)\n",
    "    split_train_score(option, df['binary_label'], lr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        293          0\n",
      "Positives        256          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        307          0\n",
      "Positives        242          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        310          0\n",
      "Positives        239          0\n",
      "\n",
      "TF-IDF_with_wb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        296          0\n",
      "Positives        253          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        279          0\n",
      "Positives        270          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        289          0\n",
      "Positives        260          0\n",
      "\n",
      "CountVectorizer\n",
      "Precision: 0.491 / Recall: 0.347 / Accuracy: 1.0 / Fscore: 0.407\n",
      "           Negatives  Positives\n",
      "Negatives        216         88\n",
      "Positives        160         85\n",
      "Precision: 0.534 / Recall: 0.351 / Accuracy: 1.0 / Fscore: 0.423\n",
      "           Negatives  Positives\n",
      "Negatives        199         82\n",
      "Positives        174         94\n",
      "Precision: 0.543 / Recall: 0.369 / Accuracy: 1.0 / Fscore: 0.439\n",
      "           Negatives  Positives\n",
      "Negatives        215         79\n",
      "Positives        161         94\n",
      "\n",
      "CountVectorizer_with_wb\n",
      "Precision: 0.915 / Recall: 0.9 / Accuracy: 1.0 / Fscore: 0.907\n",
      "           Negatives  Positives\n",
      "Negatives        278         21\n",
      "Positives         25        225\n",
      "Precision: 0.921 / Recall: 0.899 / Accuracy: 1.0 / Fscore: 0.91\n",
      "           Negatives  Positives\n",
      "Negatives        282         19\n",
      "Positives         25        223\n",
      "Precision: 0.893 / Recall: 0.893 / Accuracy: 1.0 / Fscore: 0.893\n",
      "           Negatives  Positives\n",
      "Negatives        281         26\n",
      "Positives         26        216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "for index, option in options.items():\n",
    "    print(index)\n",
    "    split_train_score(option, df['binary_label'], rf)\n",
    "    split_train_score(option, df['binary_label'], rf)\n",
    "    split_train_score(option, df['binary_label'], rf)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        289          0\n",
      "Positives        260          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        296          0\n",
      "Positives        253          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        301          0\n",
      "Positives        248          0\n",
      "\n",
      "TF-IDF_with_wb\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        300          0\n",
      "Positives        249          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        306          0\n",
      "Positives        243          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        294          0\n",
      "Positives        255          0\n",
      "\n",
      "CountVectorizer\n",
      "Precision: 0.539 / Recall: 0.355 / Accuracy: 1.0 / Fscore: 0.428\n",
      "           Negatives  Positives\n",
      "Negatives        222         76\n",
      "Positives        162         89\n",
      "Precision: 0.541 / Recall: 0.372 / Accuracy: 1.0 / Fscore: 0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Negatives  Positives\n",
      "Negatives        220         79\n",
      "Positives        157         93\n",
      "Precision: 0.536 / Recall: 0.374 / Accuracy: 1.0 / Fscore: 0.44\n",
      "           Negatives  Positives\n",
      "Negatives        202         85\n",
      "Positives        164         98\n",
      "\n",
      "CountVectorizer_with_wb\n",
      "Precision: 0.905 / Recall: 0.898 / Accuracy: 1.0 / Fscore: 0.901\n",
      "           Negatives  Positives\n",
      "Negatives        282         23\n",
      "Positives         25        219\n",
      "Precision: 0.924 / Recall: 0.878 / Accuracy: 1.0 / Fscore: 0.9\n",
      "           Negatives  Positives\n",
      "Negatives        295         17\n",
      "Positives         29        208\n",
      "Precision: 0.9 / Recall: 0.857 / Accuracy: 1.0 / Fscore: 0.878\n",
      "           Negatives  Positives\n",
      "Negatives        274         24\n",
      "Positives         36        215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "for index, option in options.items():\n",
    "    print(index)\n",
    "    split_train_score(option, df['binary_label'], mnb)\n",
    "    split_train_score(option, df['binary_label'], mnb)\n",
    "    split_train_score(option, df['binary_label'], mnb)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        290          0\n",
      "Positives        259          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        317          0\n",
      "Positives        232          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        297          0\n",
      "Positives        252          0\n",
      "\n",
      "TF-IDF_with_wb\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        305          0\n",
      "Positives        244          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        296          0\n",
      "Positives        253          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        319          0\n",
      "Positives        230          0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CountVectorizer\n",
      "Precision: 0.423 / Recall: 0.306 / Accuracy: 1.0 / Fscore: 0.355\n",
      "           Negatives  Positives\n",
      "Negatives        220         97\n",
      "Positives        161         71\n",
      "Precision: 0.528 / Recall: 0.378 / Accuracy: 1.0 / Fscore: 0.441\n",
      "           Negatives  Positives\n",
      "Negatives        213         85\n",
      "Positives        156         95\n",
      "Precision: 0.508 / Recall: 0.364 / Accuracy: 1.0 / Fscore: 0.424\n",
      "           Negatives  Positives\n",
      "Negatives        207         89\n",
      "Positives        161         92\n",
      "\n",
      "CountVectorizer_with_wb\n",
      "Precision: 0.906 / Recall: 0.902 / Accuracy: 1.0 / Fscore: 0.904\n",
      "           Negatives  Positives\n",
      "Negatives        281         23\n",
      "Positives         24        221\n",
      "Precision: 0.907 / Recall: 0.907 / Accuracy: 1.0 / Fscore: 0.907\n",
      "           Negatives  Positives\n",
      "Negatives        279         23\n",
      "Positives         23        224\n",
      "Precision: 0.917 / Recall: 0.894 / Accuracy: 1.0 / Fscore: 0.905\n",
      "           Negatives  Positives\n",
      "Negatives        283         20\n",
      "Positives         26        220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None) # params only copied\n",
    "\n",
    "for index, option in options.items():\n",
    "    print(index)\n",
    "    split_train_score(option, df['binary_label'], svm)\n",
    "    split_train_score(option, df['binary_label'], svm)\n",
    "    split_train_score(option, df['binary_label'], svm)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> option 'char_wb' on count vectorizer seems to improve the results significantly on almost every algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare cv with char_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_score_compare(features, labels, clf):\n",
    "    \n",
    "    # split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    #train    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # score\n",
    "    from sklearn.metrics import precision_recall_fscore_support as score\n",
    "    y_pred = lr.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary') # pos_label= wenn nicht binary, dann label angeben\n",
    "    return round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_pred)), round(fscore, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.926   0.926       1.0   0.926\n",
      "2   mnb      0.935   0.904       1.0   0.919\n",
      "3   svm      0.923   0.904       1.0   0.913\n",
      "0    lr      0.727   0.703       1.0   0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.938   0.911       1.0   0.924\n",
      "2   mnb      0.924   0.920       1.0   0.922\n",
      "1    rf      0.915   0.918       1.0   0.916\n",
      "0    lr      0.759   0.660       1.0   0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.941   0.918       1.0   0.929\n",
      "3   svm      0.946   0.912       1.0   0.928\n",
      "1    rf      0.927   0.890       1.0   0.908\n",
      "0    lr      0.759   0.688       1.0   0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.937   0.886       1.0   0.911\n",
      "3   svm      0.903   0.915       1.0   0.909\n",
      "2   mnb      0.903   0.896       1.0   0.900\n",
      "0    lr      0.691   0.689       1.0   0.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.946   0.923       1.0   0.935\n",
      "3   svm      0.930   0.930       1.0   0.930\n",
      "2   mnb      0.925   0.925       1.0   0.925\n",
      "0    lr      0.756   0.723       1.0   0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.911   0.900       1.0   0.906\n",
      "3   svm      0.900   0.896       1.0   0.898\n",
      "2   mnb      0.883   0.898       1.0   0.891\n",
      "0    lr      0.700   0.709       1.0   0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.904   0.922       1.0   0.913\n",
      "3   svm      0.913   0.902       1.0   0.908\n",
      "1    rf      0.890   0.912       1.0   0.901\n",
      "0    lr      0.697   0.727       1.0   0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.935   0.923       1.0   0.929\n",
      "3   svm      0.919   0.894       1.0   0.906\n",
      "1    rf      0.902   0.883       1.0   0.893\n",
      "0    lr      0.756   0.678       1.0   0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.935   0.917       1.0   0.926\n",
      "3   svm      0.943   0.878       1.0   0.909\n",
      "2   mnb      0.921   0.884       1.0   0.902\n",
      "0    lr      0.760   0.682       1.0   0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.967   0.897       1.0   0.931\n",
      "2   mnb      0.945   0.910       1.0   0.927\n",
      "3   svm      0.926   0.903       1.0   0.914\n",
      "0    lr      0.781   0.697       1.0   0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.941   0.899       1.0   0.919\n",
      "1    rf      0.932   0.884       1.0   0.908\n",
      "2   mnb      0.923   0.882       1.0   0.902\n",
      "0    lr      0.770   0.642       1.0   0.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.931   0.938       1.0   0.935\n",
      "2   mnb      0.932   0.932       1.0   0.932\n",
      "1    rf      0.923   0.904       1.0   0.913\n",
      "0    lr      0.753   0.722       1.0   0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.940   0.936       1.0   0.938\n",
      "1    rf      0.912   0.900       1.0   0.906\n",
      "2   mnb      0.907   0.887       1.0   0.897\n",
      "0    lr      0.721   0.690       1.0   0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.915   0.919       1.0   0.917\n",
      "3   svm      0.912   0.909       1.0   0.911\n",
      "1    rf      0.908   0.897       1.0   0.902\n",
      "0    lr      0.721   0.715       1.0   0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.963   0.924       1.0   0.943\n",
      "1    rf      0.946   0.890       1.0   0.917\n",
      "3   svm      0.899   0.910       1.0   0.904\n",
      "0    lr      0.764   0.699       1.0   0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.941   0.948       1.0   0.944\n",
      "2   mnb      0.935   0.935       1.0   0.935\n",
      "3   svm      0.935   0.924       1.0   0.929\n",
      "0    lr      0.759   0.718       1.0   0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.940   0.925       1.0   0.933\n",
      "1    rf      0.929   0.902       1.0   0.915\n",
      "3   svm      0.911   0.900       1.0   0.905\n",
      "0    lr      0.751   0.700       1.0   0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.939   0.935       1.0   0.937\n",
      "1    rf      0.946   0.925       1.0   0.936\n",
      "3   svm      0.891   0.916       1.0   0.903\n",
      "0    lr      0.727   0.759       1.0   0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.942   0.938       1.0   0.940\n",
      "2   mnb      0.933   0.917       1.0   0.925\n",
      "3   svm      0.948   0.894       1.0   0.920\n",
      "0    lr      0.771   0.686       1.0   0.726\n",
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.927   0.912       1.0   0.920\n",
      "2   mnb      0.927   0.896       1.0   0.911\n",
      "1    rf      0.895   0.922       1.0   0.908\n",
      "0    lr      0.740   0.676       1.0   0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rf', 0.926, 1.0),\n",
       " ('svm', 0.924, 1.0),\n",
       " ('mnb', 0.929, 1.0),\n",
       " ('rf', 0.911, 1.0),\n",
       " ('rf', 0.935, 1.0),\n",
       " ('rf', 0.906, 1.0),\n",
       " ('mnb', 0.913, 1.0),\n",
       " ('mnb', 0.929, 1.0),\n",
       " ('rf', 0.926, 1.0),\n",
       " ('rf', 0.931, 1.0),\n",
       " ('svm', 0.919, 1.0),\n",
       " ('svm', 0.935, 1.0),\n",
       " ('svm', 0.938, 1.0),\n",
       " ('mnb', 0.917, 1.0),\n",
       " ('mnb', 0.943, 1.0),\n",
       " ('rf', 0.944, 1.0),\n",
       " ('mnb', 0.933, 1.0),\n",
       " ('mnb', 0.937, 1.0),\n",
       " ('rf', 0.94, 1.0),\n",
       " ('svm', 0.92, 1.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner_algo = []\n",
    "for i in range(20):\n",
    "    scores['lr'] = split_train_score_compare(count_wb_features, df['binary_label'], lr)\n",
    "    scores['rf'] = split_train_score_compare(count_wb_features, df['binary_label'], rf)\n",
    "    scores['mnb'] = split_train_score_compare(count_wb_features, df['binary_label'], mnb)\n",
    "    scores['svm'] = split_train_score_compare(count_wb_features, df['binary_label'], svm)\n",
    "    \n",
    "    score_df = pd.DataFrame(list(scores.values()), index=list(scores.keys()), columns=['precision', 'recall', 'accuracy', 'fscore']).reset_index().sort_values('fscore', ascending=False)\n",
    "    winner_algo.append((score_df.iloc[0]['index'], score_df.iloc[0]['fscore'], score_df.iloc[0]['accuracy']))\n",
    "    print(score_df)\n",
    "winner_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>fscore</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.943</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.937</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.933</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.944</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.940</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.931</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.926</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.926</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.911</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.919</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algo  fscore  accuracy\n",
       "14  mnb   0.943       1.0\n",
       "17  mnb   0.937       1.0\n",
       "16  mnb   0.933       1.0\n",
       "2   mnb   0.929       1.0\n",
       "7   mnb   0.929       1.0\n",
       "13  mnb   0.917       1.0\n",
       "6   mnb   0.913       1.0\n",
       "15   rf   0.944       1.0\n",
       "18   rf   0.940       1.0\n",
       "4    rf   0.935       1.0\n",
       "9    rf   0.931       1.0\n",
       "0    rf   0.926       1.0\n",
       "8    rf   0.926       1.0\n",
       "3    rf   0.911       1.0\n",
       "5    rf   0.906       1.0\n",
       "12  svm   0.938       1.0\n",
       "11  svm   0.935       1.0\n",
       "1   svm   0.924       1.0\n",
       "19  svm   0.920       1.0\n",
       "10  svm   0.919       1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(winner_algo, columns=['algo', 'fscore', 'accuracy']).sort_values(['algo','fscore'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_function(clf, clf_name, features, labels):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "\n",
    "    print(clf_name)\n",
    "    print('-------')\n",
    "    \n",
    "    #train    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # score\n",
    "    from sklearn.metrics import precision_recall_fscore_support as score\n",
    "    y_pred = lr.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary') # pos_label= wenn nicht binary, dann label angeben\n",
    "    print('Precision: {} / Recall: {} / Accuracy: {} / Fscore: {}'.format(round(precision, 3), \n",
    "                                                             round(recall, 3), \n",
    "                                                             round((y_pred==y_test).sum() / len(y_pred)),\n",
    "                                                             round(fscore, 3)))\n",
    "    # confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    m_df = pd.DataFrame(\n",
    "    matrix, \n",
    "    columns=[\"Negatives\", \"Positives\"],\n",
    "    index=[\"Negatives\", \"Positives\"])\n",
    "    print(m_df)\n",
    "    \n",
    "    # export\n",
    "    import pickle\n",
    "    pickle.dump(clf, open('exports/{}_model.pkl'.format(clf_name), 'wb'))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "-------\n",
      "Precision: 0.912 / Recall: 0.9 / Accuracy: 1.0 / Fscore: 0.906\n",
      "           Negatives  Positives\n",
      "Negatives        298         20\n",
      "Positives         23        208\n",
      "\n",
      "mnb\n",
      "-------\n",
      "Precision: 0.9 / Recall: 0.885 / Accuracy: 1.0 / Fscore: 0.892\n",
      "           Negatives  Positives\n",
      "Negatives        282         24\n",
      "Positives         28        215\n",
      "\n",
      "rf\n",
      "-------\n",
      "Precision: 0.922 / Recall: 0.911 / Accuracy: 1.0 / Fscore: 0.917\n",
      "           Negatives  Positives\n",
      "Negatives        282         19\n",
      "Positives         22        226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "export_function(svm, 'svm', count_wb_features, df['binary_label'])\n",
    "export_function(mnb, 'mnb', count_wb_features, df['binary_label'])\n",
    "export_function(rf, 'rf', count_wb_features, df['binary_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(count_wb_vec, open('exports/count_wb_vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
