{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich warte schon darauf, dass man die Terrorist...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holt Björn Höcke ins Boot vielleicht haben wir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deutscher, turkmenischer Abstammung bitte. Was...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wer glaubt die gehen wieder , ist einfach nur ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man wünscht sich eine schlagkräftige Bürgerweh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label\n",
       "0  Ich warte schon darauf, dass man die Terrorist...       0.0         False\n",
       "1  Holt Björn Höcke ins Boot vielleicht haben wir...       0.0         False\n",
       "2  Deutscher, turkmenischer Abstammung bitte. Was...       0.0         False\n",
       "3  Wer glaubt die gehen wieder , ist einfach nur ...       0.0         False\n",
       "4  Man wünscht sich eine schlagkräftige Bürgerweh...       0.0         False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../2_Feature_Engineering/export/randomized_balanced_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'..\\..\\0_common')\n",
    "from model_helpers import clean_all as ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich warte schon darauf, dass man die Terrorist...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holt Björn Höcke ins Boot vielleicht haben wir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deutscher, turkmenischer Abstammung bitte. Was...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wer glaubt die gehen wieder , ist einfach nur ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man wünscht sich eine schlagkräftige Bürgerweh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label\n",
       "0  Ich warte schon darauf, dass man die Terrorist...       0.0         False\n",
       "1  Holt Björn Höcke ins Boot vielleicht haben wir...       0.0         False\n",
       "2  Deutscher, turkmenischer Abstammung bitte. Was...       0.0         False\n",
       "3  Wer glaubt die gehen wieder , ist einfach nur ...       0.0         False\n",
       "4  Man wünscht sich eine schlagkräftige Bürgerweh...       0.0         False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['raw_text'].apply(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>severity</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich warte schon darauf, dass man die Terrorist...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>warte schon darauf das terroristen opfern mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holt Björn Höcke ins Boot vielleicht haben wir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>holt björn höcke boot vielleicht letzte chance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deutscher, turkmenischer Abstammung bitte. Was...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>deutscher turkmenischer abstammung bitte graue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wer glaubt die gehen wieder , ist einfach nur ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wer glaubt gehen einfach blauäugig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man wünscht sich eine schlagkräftige Bürgerweh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wünscht schlagkräftige bürgerwehr sophienhof p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  severity  binary_label  \\\n",
       "0  Ich warte schon darauf, dass man die Terrorist...       0.0         False   \n",
       "1  Holt Björn Höcke ins Boot vielleicht haben wir...       0.0         False   \n",
       "2  Deutscher, turkmenischer Abstammung bitte. Was...       0.0         False   \n",
       "3  Wer glaubt die gehen wieder , ist einfach nur ...       0.0         False   \n",
       "4  Man wünscht sich eine schlagkräftige Bürgerweh...       0.0         False   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  warte schon darauf das terroristen opfern mach...  \n",
       "1  holt björn höcke boot vielleicht letzte chance...  \n",
       "2  deutscher turkmenischer abstammung bitte graue...  \n",
       "3                wer glaubt gehen einfach blauäugig   \n",
       "4  wünscht schlagkräftige bürgerwehr sophienhof p...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(2,5), analyzer='char', stop_words='german', max_features=10000)\n",
    "tfidf_wb_vec = TfidfVectorizer(ngram_range=(2,5), analyzer='char_wb', stop_words='german', max_features=10000)\n",
    "count_vec = CountVectorizer(ngram_range=(2,5), analyzer='char', stop_words='german', max_features=10000)\n",
    "count_wb_vec = CountVectorizer(ngram_range=(2,5), analyzer='char_wb', stop_words='german', max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = tfidf_vec.fit_transform(df['cleaned_text'])\n",
    "tfidf_wb_features = tfidf_wb_vec.fit_transform(df['cleaned_text'])\n",
    "count_features = count_vec.fit_transform(df['cleaned_text'])\n",
    "count_wb_features = count_wb_vec.fit_transform(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_wb_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_wb_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_score(features, labels, clf):\n",
    "    \n",
    "    # split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    #train    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # score\n",
    "    from sklearn.metrics import precision_recall_fscore_support as score\n",
    "    y_pred = lr.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary') # pos_label= wenn nicht binary, dann label angeben\n",
    "    \n",
    "    print('Precision: {} / Recall: {} / Accuracy: {} / Fscore: {}'.format(round(precision, 3), \n",
    "                                                         round(recall, 3), \n",
    "                                                         round((y_pred==y_test).sum() / len(y_pred)),\n",
    "                                                         round(fscore, 3)))\n",
    "    # confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    m_df = pd.DataFrame(\n",
    "    matrix, \n",
    "    columns=[\"Negatives\", \"Positives\"],\n",
    "    index=[\"Negatives\", \"Positives\"])\n",
    "    print(m_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'TF-IDF': tfidf_features, 'TF-IDF_with_wb': tfidf_wb_features, 'CountVectorizer': count_features, 'CountVectorizer_with_wb': count_wb_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "Precision: 0.822 / Recall: 0.552 / Accuracy: 1.0 / Fscore: 0.66\n",
      "           Negatives  Positives\n",
      "Negatives        267         30\n",
      "Positives        113        139\n",
      "Precision: 0.91 / Recall: 0.5 / Accuracy: 1.0 / Fscore: 0.645\n",
      "           Negatives  Positives\n",
      "Negatives        253         14\n",
      "Positives        141        141\n",
      "Precision: 0.84 / Recall: 0.581 / Accuracy: 1.0 / Fscore: 0.687\n",
      "           Negatives  Positives\n",
      "Negatives        268         28\n",
      "Positives        106        147\n",
      "\n",
      "TF-IDF_with_wb\n",
      "Precision: 0.829 / Recall: 0.549 / Accuracy: 1.0 / Fscore: 0.66\n",
      "           Negatives  Positives\n",
      "Negatives        263         29\n",
      "Positives        116        141\n",
      "Precision: 0.832 / Recall: 0.605 / Accuracy: 1.0 / Fscore: 0.701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           Negatives  Positives\n",
      "Negatives        256         32\n",
      "Positives        103        158\n",
      "Precision: 0.841 / Recall: 0.54 / Accuracy: 1.0 / Fscore: 0.657\n",
      "           Negatives  Positives\n",
      "Negatives        257         27\n",
      "Positives        122        143\n",
      "\n",
      "CountVectorizer\n",
      "Precision: 0.779 / Recall: 0.69 / Accuracy: 1.0 / Fscore: 0.732\n",
      "           Negatives  Positives\n",
      "Negatives        244         50\n",
      "Positives         79        176\n",
      "Precision: 0.76 / Recall: 0.736 / Accuracy: 1.0 / Fscore: 0.748\n",
      "           Negatives  Positives\n",
      "Negatives        236         59\n",
      "Positives         67        187\n",
      "Precision: 0.752 / Recall: 0.71 / Accuracy: 1.0 / Fscore: 0.731\n",
      "           Negatives  Positives\n",
      "Negatives        238         59\n",
      "Positives         73        179\n",
      "\n",
      "CountVectorizer_with_wb\n",
      "Precision: 0.705 / Recall: 0.719 / Accuracy: 1.0 / Fscore: 0.712\n",
      "           Negatives  Positives\n",
      "Negatives        220         76\n",
      "Positives         71        182\n",
      "Precision: 0.705 / Recall: 0.733 / Accuracy: 1.0 / Fscore: 0.719\n",
      "           Negatives  Positives\n",
      "Negatives        246         71\n",
      "Positives         62        170\n",
      "Precision: 0.71 / Recall: 0.668 / Accuracy: 1.0 / Fscore: 0.688\n",
      "           Negatives  Positives\n",
      "Negatives        246         65\n",
      "Positives         79        159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "for index, option in options.items():\n",
    "    print(index)\n",
    "    split_train_score(option, df['binary_label'], lr)\n",
    "    split_train_score(option, df['binary_label'], lr)\n",
    "    split_train_score(option, df['binary_label'], lr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        316          0\n",
      "Positives        233          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        298          0\n",
      "Positives        251          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        291          0\n",
      "Positives        258          0\n",
      "\n",
      "TF-IDF_with_wb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        298          0\n",
      "Positives        251          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        320          0\n",
      "Positives        229          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        312          0\n",
      "Positives        237          0\n",
      "\n",
      "CountVectorizer\n",
      "Precision: 0.388 / Recall: 0.275 / Accuracy: 1.0 / Fscore: 0.322\n",
      "           Negatives  Positives\n",
      "Negatives        215        101\n",
      "Positives        169         64\n",
      "Precision: 0.495 / Recall: 0.357 / Accuracy: 1.0 / Fscore: 0.415\n",
      "           Negatives  Positives\n",
      "Negatives        190         96\n",
      "Positives        169         94\n",
      "Precision: 0.491 / Recall: 0.329 / Accuracy: 1.0 / Fscore: 0.394\n",
      "           Negatives  Positives\n",
      "Negatives        215         85\n",
      "Positives        167         82\n",
      "\n",
      "CountVectorizer_with_wb\n",
      "Precision: 0.918 / Recall: 0.922 / Accuracy: 1.0 / Fscore: 0.92\n",
      "           Negatives  Positives\n",
      "Negatives        286         20\n",
      "Positives         19        224\n",
      "Precision: 0.887 / Recall: 0.895 / Accuracy: 1.0 / Fscore: 0.891\n",
      "           Negatives  Positives\n",
      "Negatives        285         27\n",
      "Positives         25        212\n",
      "Precision: 0.941 / Recall: 0.914 / Accuracy: 1.0 / Fscore: 0.927\n",
      "           Negatives  Positives\n",
      "Negatives        255         16\n",
      "Positives         24        254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "for index, option in options.items():\n",
    "    print(index)\n",
    "    split_train_score(option, df['binary_label'], rf)\n",
    "    split_train_score(option, df['binary_label'], rf)\n",
    "    split_train_score(option, df['binary_label'], rf)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        287          0\n",
      "Positives        262          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        296          0\n",
      "Positives        253          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        296          0\n",
      "Positives        253          0\n",
      "\n",
      "TF-IDF_with_wb\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        319          0\n",
      "Positives        230          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        275          0\n",
      "Positives        274          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        300          0\n",
      "Positives        249          0\n",
      "\n",
      "CountVectorizer\n",
      "Precision: 0.483 / Recall: 0.351 / Accuracy: 1.0 / Fscore: 0.407\n",
      "           Negatives  Positives\n",
      "Negatives        216         91\n",
      "Positives        157         85\n",
      "Precision: 0.458 / Recall: 0.335 / Accuracy: 1.0 / Fscore: 0.387\n",
      "           Negatives  Positives\n",
      "Negatives        211         96\n",
      "Positives        161         81\n",
      "Precision: 0.508 / Recall: 0.384 / Accuracy: 1.0 / Fscore: 0.437\n",
      "           Negatives  Positives\n",
      "Negatives        213         91\n",
      "Positives        151         94\n",
      "\n",
      "CountVectorizer_with_wb\n",
      "Precision: 0.916 / Recall: 0.897 / Accuracy: 1.0 / Fscore: 0.906\n",
      "           Negatives  Positives\n",
      "Negatives        286         20\n",
      "Positives         25        218\n",
      "Precision: 0.919 / Recall: 0.902 / Accuracy: 1.0 / Fscore: 0.91\n",
      "           Negatives  Positives\n",
      "Negatives        264         21\n",
      "Positives         26        238\n",
      "Precision: 0.922 / Recall: 0.875 / Accuracy: 1.0 / Fscore: 0.898\n",
      "           Negatives  Positives\n",
      "Negatives        274         19\n",
      "Positives         32        224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "for index, option in options.items():\n",
    "    print(index)\n",
    "    split_train_score(option, df['binary_label'], mnb)\n",
    "    split_train_score(option, df['binary_label'], mnb)\n",
    "    split_train_score(option, df['binary_label'], mnb)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        308          0\n",
      "Positives        241          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        293          0\n",
      "Positives        256          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        297          0\n",
      "Positives        252          0\n",
      "\n",
      "TF-IDF_with_wb\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        310          0\n",
      "Positives        239          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        308          0\n",
      "Positives        241          0\n",
      "Precision: 0.0 / Recall: 0.0 / Accuracy: 1.0 / Fscore: 0.0\n",
      "           Negatives  Positives\n",
      "Negatives        313          0\n",
      "Positives        236          0\n",
      "\n",
      "CountVectorizer\n",
      "Precision: 0.489 / Recall: 0.362 / Accuracy: 1.0 / Fscore: 0.416\n",
      "           Negatives  Positives\n",
      "Negatives        210         93\n",
      "Positives        157         89\n",
      "Precision: 0.476 / Recall: 0.335 / Accuracy: 1.0 / Fscore: 0.393\n",
      "           Negatives  Positives\n",
      "Negatives        222         88\n",
      "Positives        159         80\n",
      "Precision: 0.483 / Recall: 0.339 / Accuracy: 1.0 / Fscore: 0.398\n",
      "           Negatives  Positives\n",
      "Negatives        211         90\n",
      "Positives        164         84\n",
      "\n",
      "CountVectorizer_with_wb\n",
      "Precision: 0.932 / Recall: 0.902 / Accuracy: 1.0 / Fscore: 0.917\n",
      "           Negatives  Positives\n",
      "Negatives        289         16\n",
      "Positives         24        220\n",
      "Precision: 0.924 / Recall: 0.92 / Accuracy: 1.0 / Fscore: 0.922\n",
      "           Negatives  Positives\n",
      "Negatives        280         19\n",
      "Positives         20        230\n",
      "Precision: 0.943 / Recall: 0.939 / Accuracy: 1.0 / Fscore: 0.941\n",
      "           Negatives  Positives\n",
      "Negatives        290         14\n",
      "Positives         15        230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None) # params only copied\n",
    "\n",
    "for index, option in options.items():\n",
    "    print(index)\n",
    "    split_train_score(option, df['binary_label'], svm)\n",
    "    split_train_score(option, df['binary_label'], svm)\n",
    "    split_train_score(option, df['binary_label'], svm)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> option 'char_wb' on count vectorizer seems to improve the results significantly on almost every algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare cv with char_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_score_compare(features, labels, clf):\n",
    "    \n",
    "    # split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    #train    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # score\n",
    "    from sklearn.metrics import precision_recall_fscore_support as score\n",
    "    y_pred = lr.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary') # pos_label= wenn nicht binary, dann label angeben\n",
    "    return round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_pred)), round(fscore, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.951   0.886       1.0   0.917\n",
      "3   svm      0.931   0.871       1.0   0.900\n",
      "2   mnb      0.914   0.883       1.0   0.898\n",
      "0    lr      0.785   0.651       1.0   0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.945   0.932       1.0   0.938\n",
      "1    rf      0.943   0.909       1.0   0.926\n",
      "2   mnb      0.930   0.911       1.0   0.920\n",
      "0    lr      0.748   0.715       1.0   0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.927   0.919       1.0   0.923\n",
      "2   mnb      0.904   0.943       1.0   0.923\n",
      "3   svm      0.909   0.913       1.0   0.911\n",
      "0    lr      0.723   0.767       1.0   0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.919   0.919       1.0   0.919\n",
      "2   mnb      0.923   0.907       1.0   0.915\n",
      "3   svm      0.892   0.889       1.0   0.891\n",
      "0    lr      0.714   0.702       1.0   0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.941   0.916       1.0   0.929\n",
      "3   svm      0.921   0.906       1.0   0.914\n",
      "2   mnb      0.936   0.874       1.0   0.904\n",
      "0    lr      0.762   0.706       1.0   0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.948   0.919       1.0   0.933\n",
      "2   mnb      0.934   0.901       1.0   0.917\n",
      "1    rf      0.920   0.897       1.0   0.908\n",
      "0    lr      0.758   0.692       1.0   0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.938   0.926       1.0   0.932\n",
      "1    rf      0.932   0.903       1.0   0.917\n",
      "2   mnb      0.931   0.898       1.0   0.914\n",
      "0    lr      0.734   0.713       1.0   0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.924   0.913       1.0   0.918\n",
      "2   mnb      0.898   0.916       1.0   0.907\n",
      "3   svm      0.909   0.902       1.0   0.905\n",
      "0    lr      0.712   0.695       1.0   0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.915   0.911       1.0   0.913\n",
      "1    rf      0.926   0.896       1.0   0.911\n",
      "2   mnb      0.926   0.872       1.0   0.898\n",
      "0    lr      0.719   0.653       1.0   0.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.894   0.930       1.0   0.912\n",
      "2   mnb      0.891   0.922       1.0   0.906\n",
      "1    rf      0.918   0.882       1.0   0.900\n",
      "0    lr      0.711   0.717       1.0   0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.925   0.925       1.0   0.925\n",
      "1    rf      0.929   0.912       1.0   0.920\n",
      "2   mnb      0.903   0.918       1.0   0.910\n",
      "0    lr      0.720   0.693       1.0   0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.932   0.891       1.0   0.911\n",
      "3   svm      0.920   0.893       1.0   0.906\n",
      "1    rf      0.899   0.856       1.0   0.877\n",
      "0    lr      0.738   0.707       1.0   0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.937   0.918       1.0   0.928\n",
      "3   svm      0.922   0.919       1.0   0.921\n",
      "1    rf      0.916   0.912       1.0   0.914\n",
      "0    lr      0.748   0.727       1.0   0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.936   0.921       1.0   0.929\n",
      "3   svm      0.921   0.929       1.0   0.925\n",
      "1    rf      0.912   0.908       1.0   0.910\n",
      "0    lr      0.719   0.677       1.0   0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.925   0.925       1.0   0.925\n",
      "1    rf      0.924   0.924       1.0   0.924\n",
      "2   mnb      0.926   0.911       1.0   0.918\n",
      "0    lr      0.736   0.718       1.0   0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.954   0.912       1.0   0.933\n",
      "2   mnb      0.939   0.917       1.0   0.928\n",
      "1    rf      0.930   0.906       1.0   0.918\n",
      "0    lr      0.790   0.749       1.0   0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "1    rf      0.962   0.907       1.0   0.934\n",
      "2   mnb      0.936   0.917       1.0   0.927\n",
      "3   svm      0.939   0.878       1.0   0.908\n",
      "0    lr      0.780   0.685       1.0   0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.957   0.907       1.0   0.932\n",
      "1    rf      0.909   0.916       1.0   0.913\n",
      "3   svm      0.920   0.885       1.0   0.902\n",
      "0    lr      0.733   0.691       1.0   0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  precision  recall  accuracy  fscore\n",
      "3   svm      0.901   0.917       1.0   0.909\n",
      "1    rf      0.923   0.890       1.0   0.906\n",
      "2   mnb      0.908   0.901       1.0   0.904\n",
      "0    lr      0.737   0.696       1.0   0.716\n",
      "  index  precision  recall  accuracy  fscore\n",
      "2   mnb      0.940   0.916       1.0   0.928\n",
      "1    rf      0.933   0.902       1.0   0.917\n",
      "3   svm      0.930   0.897       1.0   0.913\n",
      "0    lr      0.752   0.690       1.0   0.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pascal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rf', 0.917, 1.0),\n",
       " ('svm', 0.938, 1.0),\n",
       " ('rf', 0.923, 1.0),\n",
       " ('rf', 0.919, 1.0),\n",
       " ('rf', 0.929, 1.0),\n",
       " ('svm', 0.933, 1.0),\n",
       " ('svm', 0.932, 1.0),\n",
       " ('rf', 0.918, 1.0),\n",
       " ('svm', 0.913, 1.0),\n",
       " ('svm', 0.912, 1.0),\n",
       " ('svm', 0.925, 1.0),\n",
       " ('mnb', 0.911, 1.0),\n",
       " ('mnb', 0.928, 1.0),\n",
       " ('mnb', 0.929, 1.0),\n",
       " ('svm', 0.925, 1.0),\n",
       " ('svm', 0.933, 1.0),\n",
       " ('rf', 0.934, 1.0),\n",
       " ('mnb', 0.932, 1.0),\n",
       " ('svm', 0.909, 1.0),\n",
       " ('mnb', 0.928, 1.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner_algo = []\n",
    "for i in range(20):\n",
    "    scores['lr'] = split_train_score_compare(count_wb_features, df['binary_label'], lr)\n",
    "    scores['rf'] = split_train_score_compare(count_wb_features, df['binary_label'], rf)\n",
    "    scores['mnb'] = split_train_score_compare(count_wb_features, df['binary_label'], mnb)\n",
    "    scores['svm'] = split_train_score_compare(count_wb_features, df['binary_label'], svm)\n",
    "    \n",
    "    score_df = pd.DataFrame(list(scores.values()), index=list(scores.keys()), columns=['precision', 'recall', 'accuracy', 'fscore']).reset_index().sort_values('fscore', ascending=False)\n",
    "    winner_algo.append((score_df.iloc[0]['index'], score_df.iloc[0]['fscore'], score_df.iloc[0]['accuracy']))\n",
    "    print(score_df)\n",
    "winner_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>fscore</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.932</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.928</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.928</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.911</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.934</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.923</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.919</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.933</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.933</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.932</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.912</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algo  fscore  accuracy\n",
       "17  mnb   0.932       1.0\n",
       "13  mnb   0.929       1.0\n",
       "12  mnb   0.928       1.0\n",
       "19  mnb   0.928       1.0\n",
       "11  mnb   0.911       1.0\n",
       "16   rf   0.934       1.0\n",
       "4    rf   0.929       1.0\n",
       "2    rf   0.923       1.0\n",
       "3    rf   0.919       1.0\n",
       "7    rf   0.918       1.0\n",
       "0    rf   0.917       1.0\n",
       "1   svm   0.938       1.0\n",
       "5   svm   0.933       1.0\n",
       "15  svm   0.933       1.0\n",
       "6   svm   0.932       1.0\n",
       "10  svm   0.925       1.0\n",
       "14  svm   0.925       1.0\n",
       "8   svm   0.913       1.0\n",
       "9   svm   0.912       1.0\n",
       "18  svm   0.909       1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(winner_algo, columns=['algo', 'fscore', 'accuracy']).sort_values(['algo','fscore'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_function(clf, clf_name, features, labels):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "\n",
    "    print(clf_name)\n",
    "    print('-------')\n",
    "    \n",
    "    #train    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # score\n",
    "    from sklearn.metrics import precision_recall_fscore_support as score\n",
    "    y_pred = lr.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label=True, average='binary') # pos_label= wenn nicht binary, dann label angeben\n",
    "    print('Precision: {} / Recall: {} / Accuracy: {} / Fscore: {}'.format(round(precision, 3), \n",
    "                                                             round(recall, 3), \n",
    "                                                             round((y_pred==y_test).sum() / len(y_pred)),\n",
    "                                                             round(fscore, 3)))\n",
    "    # confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    m_df = pd.DataFrame(\n",
    "    matrix, \n",
    "    columns=[\"Negatives\", \"Positives\"],\n",
    "    index=[\"Negatives\", \"Positives\"])\n",
    "    print(m_df)\n",
    "    \n",
    "    # export\n",
    "    import pickle\n",
    "    pickle.dump(clf, open('exports/{}_model.pkl'.format(clf_name), 'wb'))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "-------\n",
      "Precision: 0.932 / Recall: 0.893 / Accuracy: 1.0 / Fscore: 0.912\n",
      "           Negatives  Positives\n",
      "Negatives        289         16\n",
      "Positives         26        218\n",
      "\n",
      "mnb\n",
      "-------\n",
      "Precision: 0.935 / Recall: 0.91 / Accuracy: 1.0 / Fscore: 0.922\n",
      "           Negatives  Positives\n",
      "Negatives        314         14\n",
      "Positives         20        201\n",
      "\n",
      "rf\n",
      "-------\n",
      "Precision: 0.936 / Recall: 0.877 / Accuracy: 1.0 / Fscore: 0.906\n",
      "           Negatives  Positives\n",
      "Negatives        282         15\n",
      "Positives         31        221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "export_function(svm, 'svm', count_wb_features, df['binary_label'])\n",
    "export_function(mnb, 'mnb', count_wb_features, df['binary_label'])\n",
    "export_function(rf, 'rf', count_wb_features, df['binary_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
